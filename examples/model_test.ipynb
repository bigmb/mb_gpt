{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7f7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb.gpt.models.connecter_type1 import BasicLLM\n",
    "from mb.gpt.models.vlm_encoder_clip import VlmEncoderTest\n",
    "from mb.gpt.models.text_encoder_smalvlm import TextEncoderTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1bf9245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLLM(embedding_dim=256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_encoder = VlmEncoderTest(128,128)\n",
    "text_encoder = TextEncoderTest(256,64)\n",
    "model = BasicLLM(vlm_emb_dim=128, text_emb_dim=64, embedding_dim=256)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17aa8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLLM(embedding_dim=256)\n",
      "Linear(in_features=192, out_features=256, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a729b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.randn(10, 128)  # Simulated VLM embedding\n",
    "data2 = torch.randn(10, 256)   # Simulated text embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44016850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2105,  1.0456,  2.1830,  0.0887, -0.7237,  0.3205, -1.1705, -1.0274,\n",
       "         0.2224,  0.1359])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a30f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm_data = vlm_encoder(data1)\n",
    "text_data = text_encoder(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2777f6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0598, -0.0019,  0.0545,  ...,  0.0385,  0.0752,  0.0125],\n",
       "        [-0.0160, -0.0144, -0.0794,  ...,  0.0388, -0.0173,  0.0681],\n",
       "        [ 0.0487, -0.0142, -0.0423,  ..., -0.0376,  0.0085,  0.0322],\n",
       "        ...,\n",
       "        [ 0.0200,  0.0174, -0.0591,  ...,  0.0568, -0.0788, -0.0445],\n",
       "        [ 0.0400,  0.0727, -0.0876,  ...,  0.0308, -0.0400,  0.0083],\n",
       "        [ 0.0544, -0.0225, -0.0853,  ...,  0.0513,  0.0734, -0.0573]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_encoder.state_dict()['linear.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3992877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    list(vlm_encoder.parameters()) + list(text_encoder.parameters()) + list(model.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "optimizer.zero_grad()\n",
    "output = model(vlm_data, text_data,None)\n",
    "loss = output.sum()  # Dummy loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59214408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0608, -0.0029,  0.0555,  ...,  0.0395,  0.0762,  0.0135],\n",
       "        [-0.0170, -0.0134, -0.0804,  ...,  0.0378, -0.0183,  0.0671],\n",
       "        [ 0.0497, -0.0152, -0.0413,  ..., -0.0366,  0.0095,  0.0332],\n",
       "        ...,\n",
       "        [ 0.0210,  0.0164, -0.0581,  ...,  0.0578, -0.0778, -0.0435],\n",
       "        [ 0.0410,  0.0717, -0.0866,  ...,  0.0318, -0.0390,  0.0093],\n",
       "        [ 0.0534, -0.0215, -0.0863,  ...,  0.0503,  0.0724, -0.0583]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_encoder.state_dict()['linear.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7996a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb8189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f5501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fb8bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Optional\n",
    "\n",
    "class BasicLLM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vlm_encoder: nn.Module,\n",
    "                 text_encoder: nn.Module,\n",
    "                 vlm_emb_dim: Optional[int] = None,\n",
    "                 text_emb_dim: Optional[int] = None,\n",
    "                 output_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vlm_encoder = vlm_encoder if vlm_encoder is not None else nn.Identity()\n",
    "        self.text_encoder = text_encoder if text_encoder is not None else nn.Identity()\n",
    "\n",
    "        if vlm_emb_dim is not None and text_emb_dim is not None:\n",
    "            self.linear1 = nn.Linear(vlm_emb_dim + text_emb_dim, output_classes)\n",
    "        else:\n",
    "            self.linear1 = nn.LazyLinear(output_classes)\n",
    "\n",
    "    def forward(self, \n",
    "                vlm_emb: torch.Tensor, \n",
    "                text_emb: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        vlm_emb = self.vlm_encoder(vlm_emb)\n",
    "        text_emb = self.text_encoder(text_emb)\n",
    "\n",
    "        combined_emb = torch.cat([vlm_emb, text_emb], dim=-1)\n",
    "\n",
    "        projected_emb = self.linear1(combined_emb)\n",
    "\n",
    "        if projected_emb.dim() == 2:\n",
    "            projected_emb = projected_emb.unsqueeze(1)\n",
    "\n",
    "        return projected_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0993c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VlmEncoderTest(nn.Module):\n",
    "    def __init__(self,in_dim=512,out_dim=128):\n",
    "        super(VlmEncoderTest, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "            return self.linear(x)\n",
    "        \n",
    "class TextEncoderTest(nn.Module):\n",
    "    def __init__(self,in_dim=512,out_dim=128):\n",
    "        super(TextEncoderTest, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e45d932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLLM(\n",
       "  (vlm_encoder): VlmEncoderTest(\n",
       "    (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (text_encoder): TextEncoderTest(\n",
       "    (linear): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (linear1): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlm_encoder = VlmEncoderTest(in_dim=128, out_dim=128)\n",
    "text_encoder = TextEncoderTest(in_dim=256, out_dim=64)\n",
    "model = BasicLLM(\n",
    "    vlm_encoder=vlm_encoder,\n",
    "    text_encoder=text_encoder,\n",
    "    # vlm_emb_dim=128,\n",
    "    # text_emb_dim=64,\n",
    "    output_classes=10,\n",
    " )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "033eca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09a6cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_fit_in_single_gpu(\n",
    "    model,\n",
    "    batch_size=10,\n",
    "    vlm_input_dim=128,\n",
    "    text_input_dim=256,\n",
    "    dtype=torch.float32,\n",
    "    device='cuda:0',\n",
    "):\n",
    "    if not torch.cuda.is_available():\n",
    "        print('CUDA is not available on this machine.')\n",
    "        return False\n",
    "\n",
    "    model = model.to(device).eval()\n",
    "    vlm_x = torch.randn(batch_size, vlm_input_dim, dtype=dtype, device=device)\n",
    "    text_x = torch.randn(batch_size, text_input_dim, dtype=dtype, device=device)\n",
    "\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats(device=device)\n",
    "        with torch.no_grad():\n",
    "            _ = model(vlm_x, text_x)\n",
    "        peak_mb = torch.cuda.max_memory_allocated(device=device) / (1024 ** 2)\n",
    "        print(f'Fits on {device}. Peak allocated: {peak_mb:.2f} MB')\n",
    "        return True\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e).lower():\n",
    "            print(f'OOM on {device}: {e}')\n",
    "            return False\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b53087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits on cuda:0. Peak allocated: 9.30 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_fit_in_single_gpu(\n",
    "    model,\n",
    "    batch_size=10,\n",
    "    vlm_input_dim=128,\n",
    "    text_input_dim=256,\n",
    "    device='cuda:0',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f76ec889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_fit_training_step(\n",
    "    model,\n",
    "    batch_size=10,\n",
    "    vlm_input_dim=128,\n",
    "    text_input_dim=256,\n",
    "    dtype=torch.float32,\n",
    "    device='cuda:0',\n",
    "    lr=1e-3,\n",
    "):\n",
    "    if not torch.cuda.is_available():\n",
    "        print('CUDA is not available on this machine.')\n",
    "        return False\n",
    "\n",
    "    model = model.to(device).train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    vlm_x = torch.randn(batch_size, vlm_input_dim, dtype=dtype, device=device)\n",
    "    text_x = torch.randn(batch_size, text_input_dim, dtype=dtype, device=device)\n",
    "\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats(device=device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        out = model(vlm_x, text_x)\n",
    "        loss = out.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        peak_mb = torch.cuda.max_memory_allocated(device=device) / (1024 ** 2)\n",
    "        print(f'Training step fits on {device}. Peak allocated: {peak_mb:.2f} MB')\n",
    "        return True\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e).lower():\n",
    "            print(f'OOM on {device}: {e}')\n",
    "            return False\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0ee58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step fits on cuda:0. Peak allocated: 17.93 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_fit_training_step(model,\n",
    "    batch_size=10,\n",
    "    vlm_input_dim=128,\n",
    "    text_input_dim=256,\n",
    "    device='cuda:0',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c5cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fd242",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mb.gpt.utils.gpu_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gpus_by_least_usage\n\u001b[1;32m      2\u001b[0m get_gpus_by_least_usage(return_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mb.gpt.utils.gpu_tools'"
     ]
    }
   ],
   "source": [
    "from mb.gpt.utils.gpu_tools import get_gpus_by_least_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abaa9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gpu_id': 0,\n",
       "  'name': 'NVIDIA TITAN RTX',\n",
       "  'free_gb': 22.35418701171875,\n",
       "  'used_gb': 1.26904296875,\n",
       "  'total_gb': 23.62322998046875,\n",
       "  'usage_ratio': 0.05372012928796025}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpus_by_least_usage(return_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5309bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549cf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
